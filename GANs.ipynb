{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import generate\n",
    "import plot\n",
    "import models\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fake results\n",
    "half = 500\n",
    "labels = np.array([1]*half + [0]*half)\n",
    "logits = np.random.uniform(size=2*half)\n",
    "    \n",
    "# make a test plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plot.data1D(ax[0], generate.triangular1D(100), generate.triangular1D(100))\n",
    "plot.roc_curve(ax[1], labels, logits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 3\n",
    "\n",
    "noise = generate.input_noise(300, NOISE_DIM)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "_ = ax.scatter(noise[:, 0], noise[:, 1], alpha=0.7)\n",
    "_ = ax.set_xlabel('noise dimension 1')\n",
    "_ = ax.set_ylabel('noise dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the graphs and run the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024 #Â  2x for the adversary, which gets both real and fake data\n",
    "N_PRE_STEPS = 100\n",
    "N_STEPS = 300\n",
    "N_DRAW = 10\n",
    "COUNTER+=1 # so that new graphs are created each time\n",
    "\n",
    "# create the input placeholders\n",
    "T_input_noise = tf.placeholder(tf.float32, shape=(BATCH_SIZE, NOISE_DIM), name='InputNoise')\n",
    "T_real_data = tf.placeholder(tf.float32, shape=(BATCH_SIZE, 1), name='DataBatch')\n",
    "\n",
    "# create the computational graph for the fake data\n",
    "T_fake_data, vars_G = models.Generator1D(T_input_noise, name='MyGenerator1D_{}'.format(COUNTER))\n",
    "TB_fake_data = tf.summary.histogram('fake_data', T_fake_data)\n",
    "\n",
    "# create the input to the adversary\n",
    "T_comb_data = tf.concat([T_real_data, T_fake_data], axis=0)\n",
    "T_comb_labels = tf.one_hot(tf.constant([1]*BATCH_SIZE + [0]*BATCH_SIZE, dtype=tf.int32), depth=2)\n",
    "\n",
    "# create the adversary (discriminator)\n",
    "T_logits, vars_A = models.Adversary(T_comb_data, name='MyAdversary_{}'.format(COUNTER))\n",
    "TB_logits = tf.summary.histogram('TB_logits', T_logits)\n",
    "TB_labels = tf.summary.histogram('TB_labels', T_comb_labels)\n",
    "\n",
    "# create the optimisation graphs\n",
    "T_loss_A = tf.math.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=T_comb_labels, logits=T_logits))\n",
    "T_opt_A = tf.train.AdamOptimizer().minimize(T_loss_A, var_list=vars_A)\n",
    "TB_loss_A = tf.summary.scalar('TB_Loss_A', T_loss_A)\n",
    "\n",
    "# generator\n",
    "T_loss_G = - T_loss_A\n",
    "T_opt_G = tf.train.AdamOptimizer().minimize(T_loss_G, var_list=vars_G)\n",
    "\n",
    "# tensorboard\n",
    "merged = tf.summary.merge([TB_fake_data, TB_logits, TB_labels, TB_loss_A])\n",
    "writer = tf.summary.FileWriter(logdir='tensorboard')\n",
    "\n",
    "# make a session and initialise all variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def get_feed_dict():\n",
    "    real_data = generate.triangular1D(BATCH_SIZE)\n",
    "    input_noise = generate.input_noise(BATCH_SIZE, NOISE_DIM)\n",
    "    return {T_real_data:real_data, T_input_noise:input_noise}\n",
    "\n",
    "# first run the pretraining steps (just the discriminator)\n",
    "aurocs = []\n",
    "losses_A = []\n",
    "for i in range(N_PRE_STEPS):\n",
    "\n",
    "    # prepare the inputs\n",
    "    feed_dict = get_feed_dict()\n",
    "    \n",
    "    # run the computation (discriminator, performance monitoring)\n",
    "    _ = sess.run(T_opt_A, feed_dict=feed_dict)\n",
    "    to_run = [T_fake_data, T_comb_labels, T_logits, T_loss_A]\n",
    "    fake_data, labels, logits, loss_A = sess.run(to_run, feed_dict=feed_dict)\n",
    "    \n",
    "    # plot only N times\n",
    "    aurocs.append(roc_auc_score(labels, logits))\n",
    "    losses_A.append(loss_A)\n",
    "    do_plot = (i in [n* int(N_PRE_STEPS/N_DRAW) for n in range(N_DRAW)]) or (i == N_PRE_STEPS-1)\n",
    "    \n",
    "    if do_plot:\n",
    "        print('Pretraining step {}/{}'.format(i, N_PRE_STEPS))\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        plot.data1D(ax[0], generate.triangular1D(BATCH_SIZE), fake_data.ravel())\n",
    "        plot.roc_curve(ax[1], labels[:,1], logits[:,1])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "# now run the training steps, and plot the fake and real data\n",
    "for i in range(N_STEPS):\n",
    "    \n",
    "    # prepare the inputs\n",
    "    feed_dict = get_feed_dict()\n",
    "    \n",
    "    # run the computation (discriminator, generator, performance monitoring)\n",
    "    for _ in range(10):\n",
    "        _ = sess.run(T_opt_A, feed_dict=get_feed_dict())\n",
    "    _ = sess.run(T_opt_G, feed_dict=feed_dict)\n",
    "    to_run = [T_fake_data, T_comb_labels, T_logits, T_loss_A]\n",
    "    fake_data, labels, logits, loss_A = sess.run(to_run, feed_dict=feed_dict)\n",
    "    \n",
    "    # run summary separately\n",
    "    summary = sess.run(merged, feed_dict=feed_dict)\n",
    "    \n",
    "    # store tensorboard\n",
    "    writer.add_summary(summary, i)\n",
    "    \n",
    "    # plot only ten times\n",
    "    aurocs.append(roc_auc_score(labels, logits))\n",
    "    losses_A.append(loss_A)\n",
    "    do_plot = (i in [n* int(N_STEPS/N_DRAW) for n in range(N_DRAW)]) or (i == N_STEPS-1)\n",
    "\n",
    "    if do_plot:\n",
    "        print('Training step {}/{}'.format(i, N_STEPS))\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        plot.data1D(ax[0], generate.triangular1D(BATCH_SIZE), fake_data.ravel())\n",
    "        plot.roc_curve(ax[1], labels[:,1], logits[:,1])\n",
    "        plt.show()\n",
    "    \n",
    "print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplots=2\n",
    "fig, ax = plt.subplots(1, nplots, sharex=True, figsize=(nplots*6, 5))\n",
    "ax[0].plot(range(len(aurocs)), aurocs, c='r')\n",
    "ax[0].set_xlabel('Training steps')\n",
    "ax[0].set_ylabel('AUROC')\n",
    "ax[1].plot(range(len(losses_A)), losses_A, c='g')\n",
    "ax[1].set_xlabel('Training steps')\n",
    "ax[1].set_ylabel('Adversary loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (make-GANs-not-guns)",
   "language": "python",
   "name": "make-gans-not-guns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
